\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{amsmath}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}

\title{System Verification and Validation Plan for \progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Feb 24 & 1.0 & Notes\\
\bottomrule
\end{tabularx}



\newpage

\tableofcontents

\listoftables
\wss{Remove this section if it isn't needed}

\listoffigures
\wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations, and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{Symbol} & \textbf{Description}\\
  \midrule 
  $q$ & Joint angle (rad) \\  
  $\dot{q}$ & Joint angular velocity (rad/s) \\  
  $\ddot{q}$ & Joint angular acceleration (rad/s$^2$) \\  
  $L$ & Link length (mm) \\  
  \bottomrule
\end{tabular}\\


\newpage

\pagenumbering{arabic}

This document describes the Verification and Validation (V\&V) plan for our software system, which addresses the path-planning and inverse-kinematics (IK) verification tasks for 2D robotic manipulators. The document outlines our approach, objectives, and the tests to be performed to ensure that the system meets the specified requirements. A roadmap of the plan is as follows:
\begin{itemize}
  \item Section 1 covers general information about the software, its purpose, and the primary V\&V objectives.
  \item Section 2 provides details on the V\&V plan, the team, and the methods and tools used.
  \item Section 3 describes the system-level tests for both functional and nonfunctional requirements.
  \item Section 4 focuses on unit-level testing, including scope, test coverage, and traceability to modules.
\end{itemize}

\section{General Information}

\subsection{Summary}
The software under test is a \textbf{2D Robot Arm Path-Planning and IK Solver} for manipulators with circular obstacles. The system:
\begin{itemize}
    \item Represents the manipulator’s joints and links in a distance-geometric framework.
    \item Uses path-planning algorithms (e.g., A*) and inverse-kinematics solvers to find feasible joint angles.
    \item Ensures collision-free paths around circular obstacles.
\end{itemize}



\subsection{Objectives}

The primary objectives of the V\&V process are:
\begin{itemize}
    \item Build confidence in software correctness by systematically testing the functional requirements (e.g., path planning, collision avoidance).
    \item Demonstrate acceptable performance, including computational efficiency and accuracy of solutions.
    \item Verify reliability, so that the solution can be used for 2D manipulator control scenarios with minimal failures.
\end{itemize}
\textbf{Out of scope:}
\begin{itemize}
    \item Extensive \emph{usability} testing. We will focus on correctness and performance rather than user interface design.
    \item Verification of external libraries (e.g., numerical solvers). We assume they have been validated by their providers.
\end{itemize}

\subsection{Challenge Level and Extras}
\textbf{Challenge Level:} General (per agreement with the course instructor).
\textbf{Extras:}
\begin{itemize}
    \item A brief user manual for researchers/engineers.
    \item Potential code walkthroughs and extended design documentation, as time and resources permit.
\end{itemize}

\subsection{Relevant Documentation}
\begin{itemize}
  \item \textbf{Software Requirements Specification} (SRS) :
  This defines the required functionalities for the 2D robot arm path planner, including input constraints, output specifications, and performance requirements.
  \item \textbf{Other Project Documents} (MG, MIS, etc.):
  These documents describe the design and detailed modules of the system. They are relevant for deriving unit tests and ensuring that design decisions align with requirements.
  \item \textbf{Code Reference}:
  An example is the A* toroidal grid code for obstacle navigation, which will be referenced or adapted for verifying path-planning correctness.
\end{itemize}




\section{Plan}

This section outlines the multiple stages of the verification and validation (V\&V) process. First, the V\&V team is introduced. Then, verification plans for the SRS, design, V\&V plan, and implementation are described. Finally, automated testing and verification tools are briefly discussed.

\subsection{Verification and Validation Team}

The following personnel will be involved in the verification and validation of the 2D Robot Arm Path Planning system:

\begin{itemize}
    \item \textbf{Ziyang Fang}: The author of the program. Responsible for the creation of the V\&V plan, implementation of the tests, and analysis of results.
    \item \textbf{Dr. Spencer Smith}: The project supervisor. Responsible for reviewing the V\&V plan, test cases, and overall validation of the system.
    \item \textbf{Alaap Grandhi}: The domain expert. Responsible for reviewing the V\&V plan, ensuring scientific correctness, and verifying test coverage.
\end{itemize}

\subsection{SRS Verification Plan}

To ensure the SRS is complete, correct, and consistent, we will use the following verification methods:

\begin{itemize}
    \item \textbf{Supervisor Review}: Dr. Spencer Smith will review the SRS for completeness and clarity. A structured checklist will be provided to guide feedback.
    \item \textbf{Domain Expert Review}: Alaap Grandhi will review the SRS to ensure technical accuracy and feasibility.
    \item \textbf{Issue Tracker}: Feedback from reviews will be logged as GitHub issues, and necessary modifications will be made accordingly.
    \item \textbf{Peer Feedback}: Classmates will provide additional feedback to identify any unclear or missing requirements.
\end{itemize}


\subsection{Design Verification Plan}
\begin{itemize}
  \item \textbf{Classmate / Peer Design Review}: We will have scheduled walkthrough sessions where classmates provide feedback on the design documents (MG, MIS).
  \item \textbf{Design Checklists}: We will ensure that each requirement in the SRS is addressed at the design level. Checklists will cover topics like modularity, clarity, and traceability to requirements.
\end{itemize}


\subsection{Verification and Validation Plan Verification Plan}

\begin{itemize}
  \item \textbf{Internal Review}: The same team members will review this V\&V plan for completeness and feasibility.
  \item \textbf{Mutation of Plan}: Introduce hypothetical changes (mutations) to test if the plan remains robust and comprehensive.
\end{itemize}

\subsection{Implementation Verification Plan}

\begin{itemize}
  \item \textbf{Unit Tests}: We will write unit tests for each major component, automated by a suitable framework (e.g., \texttt{pytest} for Python).
  \item \textbf{Static Analysis}: Use a linter (e.g., \texttt{flake8}), possibly additional tools like \texttt{pylint} or \texttt{mypy}, to verify code standards and catch potential errors.
  \item \textbf{Code Walkthroughs}: During final presentations or peer sessions, we will review code segments dealing with core algorithms (IK solver, collision detection, path planning).
\end{itemize}

\subsection{Automated Testing and Verification Tools}

\begin{itemize}
  \item \textbf{Continuous Integration (CI)}: GitHub Actions is used to run automated test suites on every pull request and commit to ensure code reliability.
  \item \textbf{Unit Testing Framework}: The project uses \texttt{pytest} for unit testing, which provides powerful fixtures and easy test case management.
  \item \textbf{Coverage Analysis}: The tool \texttt{coverage.py} is used to measure code coverage, ensuring critical components are well-tested.
  \item \textbf{Static Code Analysis}: \texttt{flake8} is used to check for style violations and potential errors in Python code.
  \item \textbf{Type Checking}: \texttt{mypy} is used to enforce type annotations and detect type inconsistencies.
  \item \textbf{Performance Profiling}: \texttt{cProfile} is used for runtime performance analysis to identify bottlenecks in critical functions.
  \item \textbf{Memory Profiling}: \texttt{memory-profiler} helps track memory usage during execution to detect leaks and optimize performance.
  \item \textbf{Automated Dependency Management}: \texttt{pip-tools} is used to manage dependencies and ensure a stable development environment.
\end{itemize}



\subsection{Software Validation Plan}

\begin{itemize}
  \item \textbf{Supervisor/Stakeholder Review}: If an external stakeholder is available, we will present a demo (Rev 0) to validate the requirements match real-world needs.
  \item \textbf{Comparison with Known Benchmarks}: Use small or known scenarios to validate the solution’s correctness against expected paths/angles.
\end{itemize}

\section{System Tests}

System-level tests will address functional requirements (such as collision avoidance and path planning success) and nonfunctional requirements (such as performance and accuracy). These tests will be conducted after individual modules pass unit tests to ensure the entire system functions as expected.

\subsection{Tests for Functional Requirements}

This section defines tests for key functional areas of the \textbf{2D Robot Arm Path Planning System}, ensuring that the system correctly computes collision-free paths and valid inverse kinematics (IK) solutions. The test cases are derived from the functional requirements specified in the Software Requirements Specification (SRS).

\subsubsection{Path Planning and Obstacle Avoidance}

These tests ensure that the system can generate valid and collision-free paths from the start to the goal configuration. \textbf{Reference: SRS Sections on Path Planning and Collision-Free Paths.}

\paragraph{Collision-Free Path Generation}

\begin{enumerate}

\item \textbf{Test ID: T1}  

\textbf{Control:} Automatic  

\textbf{Initial State:}  
\begin{itemize}
    \item Defined robotic arm parameters (link lengths, joint limits)  
    \item Known obstacle positions and sizes  
    \item Initial and goal joint configurations  
\end{itemize}

\textbf{Input:}  
\begin{itemize}
    \item Initial joint angles \( q_{\text{init}} \)  
    \item Goal position \( (x_{\text{goal}}, y_{\text{goal}}) \)  
    \item Obstacle positions and radii  
\end{itemize}

\textbf{Expected Output:}  
\begin{itemize}
    \item A valid sequence of joint angles \( q(t) \) ensuring obstacle avoidance  
    \item No intersection between the arm and any obstacle  
\end{itemize}

\textbf{Test Case Derivation:} Ensures that the system correctly computes a path from the initial to the goal state while maintaining a safe clearance from obstacles.  

\textbf{How Test Will Be Performed:}  
\begin{itemize}
    \item Use predefined obstacle environments  
    \item Execute the path-planning function and validate results  
    \item Visually inspect plotted trajectories  
    \item Check computational efficiency  
\end{itemize}

\item \textbf{Test ID: T2}  

\textbf{Control:} Automatic  

\textbf{Initial State:} Same as T1  

\textbf{Input:}  
\begin{itemize}
    \item Multiple circular obstacles blocking the direct path  
\end{itemize}

\textbf{Expected Output:}  
\begin{itemize}
    \item The planned trajectory avoids all obstacles  
    \item The trajectory remains kinematically feasible  
\end{itemize}

\textbf{Test Case Derivation:} Ensures the system can handle more complex environments and still find feasible paths.  

\textbf{How Test Will Be Performed:}  
\begin{itemize}
    \item Introduce additional obstacles in varying configurations  
    \item Validate computed trajectories  
\end{itemize}

\end{enumerate}

\subsubsection{Inverse Kinematics (IK) Solver Validation}

These tests verify that the IK solver correctly computes joint angles for a given end-effector position. \textbf{Reference: SRS Section on Forward Kinematics and Inverse Kinematics.}

\paragraph{Feasibility of IK Solutions}

\begin{enumerate}

\item \textbf{Test ID: T3}  

\textbf{Control:} Automatic  

\textbf{Initial State:} Defined robotic arm parameters  

\textbf{Input:}  
\begin{itemize}
    \item A reachable target position \( (x_{\text{goal}}, y_{\text{goal}}) \)  
\end{itemize}

\textbf{Expected Output:}  
\begin{itemize}
    \item A valid set of joint angles \( (\theta_1, \theta_2) \)  
    \item The computed position matches the expected end-effector position  
\end{itemize}

\textbf{Test Case Derivation:} Ensures that inverse kinematics computations return correct and feasible joint angles.  

\textbf{How Test Will Be Performed:}  
\begin{itemize}
    \item Compute joint angles using inverse kinematics  
    \item Validate against forward kinematics  
    \item Check if solutions respect joint limits  
\end{itemize}

\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Performance and Computational Efficiency}

These tests ensure that the system computes paths within acceptable time limits and does not exceed memory constraints. \textbf{Reference: SRS Section on Accuracy and Performance.}

\begin{enumerate}

\item \textbf{Test ID: N1}  

\textbf{Type:} Performance, Automatic  

\textbf{Initial State:} None  

\textbf{Input:}  
\begin{itemize}
    \item A large number of obstacles (e.g., 50+)  
    \item Randomized goal positions  
\end{itemize}

\textbf{Expected Output:}  
\begin{itemize}
    \item Execution time statistics  
    \item Peak memory usage report  
\end{itemize}

\textbf{How Test Will Be Performed:}  
\begin{itemize}
    \item Profile the system while computing paths  
    \item Measure time-to-solution for varying complexity levels  
    \item Compare against baseline performance requirements  
\end{itemize}

\item \textbf{Test ID: N2}  

\textbf{Type:} Scalability, Automatic  

\textbf{Initial State:} None  

\textbf{Input:}  
\begin{itemize}
    \item Increasing number of degrees of freedom (DOF) in the robotic arm (e.g., from 2-DOF to 6-DOF)  
\end{itemize}

\textbf{Expected Output:}  
\begin{itemize}
    \item System performance degradation analysis  
    \item Success rate of path planning for different DOF levels  
\end{itemize}

\textbf{How Test Will Be Performed:}  
\begin{itemize}
    \item Measure computation time for different arm configurations  
    \item Evaluate feasibility of solutions at high DOF levels  
\end{itemize}

\end{enumerate}

\subsection{Traceability Between Test Cases and Requirements}

The traceability matrix below maps test cases to the corresponding requirements from the SRS to ensure complete coverage.

\begin{table}[h!]
  \centering
  \caption{Traceability Matrix for System Tests}
  \begin{tabular}{l l l}
  \toprule
  \textbf{Requirement} & \textbf{Test Case(s)} & \textbf{Comments} \\
  \midrule
  FR1: Single Obstacle Avoidance & T1 & Ensures safe navigation around obstacles \\
  FR2: Multiple Obstacles & T2 & Tests complex environment handling \\
  FR3: Solve Feasible IK & T3 & Verifies correct IK computations \\
  NFR1: Accuracy & N1 & Validates end-effector positioning accuracy \\
  NFR2: Performance & N2 & Ensures computational efficiency \\
  \bottomrule
  \end{tabular}
\end{table}


\section{Unit Test Description}
Unit testing will occur once the detailed designs are finalized (see the MIS). Below is the general approach for module-level testing.

\subsection{Unit Testing Scope}

All modules described in the MIS are considered in-scope, except for any third-party libraries. Priority is given to:
\begin{itemize}
    \item IK Solver Module
    \item Collision Detection Module
    \item Path Planner Module
\end{itemize}
We assume external math/optimization libraries (e.g., for matrix operations) are already tested by their providers.

\subsection{Tests for Functional Requirements}

\subsubsection{Collision Detection Module Tests}

\begin{enumerate}
\item \textbf{Test ID}: U1 \\ 
\textbf{Type}: Functional, Automatic \\ 
\textbf{Initial State}: Environment with at least one circular obstacle \\ 
\textbf{Input}: A line segment representing a robot arm link and an obstacle defined by center position and radius \\ 
\textbf{Expected Output}: Boolean indicating whether a collision occurs \\ 
\textbf{Test Case Derivation}: Verify collision detection under different scenarios:
\begin{itemize}
    \item No collision (link does not intersect obstacle)
    \item Tangential collision (link touches the edge of the obstacle)
    \item Full overlap (link completely inside the obstacle)
\end{itemize}
\textbf{How Test Will be Performed}: Simulate known geometries and compare algorithm outputs with analytical results.
\end{enumerate}

\subsubsection{IK Solver Module Tests}

\begin{enumerate}
\item \textbf{Test ID}: U2 \\ 
\textbf{Type}: Functional, Automatic \\ 
\textbf{Initial State}: 2-link robotic arm with fixed link lengths \\ 
\textbf{Input}: Target position in Cartesian coordinates \\ 
\textbf{Expected Output}: Set of joint angles that place the end-effector at the target \\ 
\textbf{Test Case Derivation}: Verify correctness under different conditions:
\begin{itemize}
    \item Target reachable within workspace
    \item Target at singularity points (e.g., fully extended or folded)
    \item Target unreachable (should return failure)
\end{itemize}
\textbf{How Test Will be Performed}: Compare solver results to analytical solutions and verify feasibility of output joint angles.
\end{enumerate}

\subsubsection{Path Planner Module Tests}

\begin{enumerate}
\item \textbf{Test ID}: U3 \\ 
\textbf{Type}: Functional, Automatic \\ 
\textbf{Initial State}: Defined workspace with static obstacles \\ 
\textbf{Input}: Start and goal positions, obstacle map \\ 
\textbf{Expected Output}: A sequence of joint angles forming a valid path from start to goal \\ 
\textbf{Test Case Derivation}: Ensure correct path generation under:
\begin{itemize}
    \item No obstacles (should return a direct path)
    \item Single obstacle blocking the direct path (should generate a detour)
    \item Multiple obstacles with narrow passage (should generate an optimal feasible path)
\end{itemize}
\textbf{How Test Will be Performed}: Compare generated paths with expected solutions in predefined test environments.
\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Performance and Scalability Tests}

\begin{enumerate}
\item \textbf{Test ID}: U4 \\ 
\textbf{Type}: Performance, Automatic \\ 
\textbf{Initial State}: Environment with varying numbers of obstacles \\ 
\textbf{Input}: Multiple path-planning queries with increasing workspace complexity \\ 
\textbf{Expected Output}: Execution time and memory usage statistics \\ 
\textbf{How Test Will be Performed}: Use a profiler to measure performance overhead and scalability under high computational loads.
\end{enumerate}

\subsubsection{Numerical Stability Tests}

\begin{enumerate}
\item \textbf{Test ID}: U5 \\ 
\textbf{Type}: Accuracy, Automatic \\ 
\textbf{Initial State}: Workspace with no obstacles \\ 
\textbf{Input}: Multiple IK queries with floating-point precision limits \\ 
\textbf{Expected Output}: Consistent and numerically stable joint angles \\ 
\textbf{How Test Will be Performed}: Compare solver results with high-precision analytical solutions and detect anomalies in floating-point calculations.
\end{enumerate}

\subsection{Traceability Between Test Cases and Modules}

\begin{table}[h!]
  \centering
  \caption{Traceability Matrix for Unit Tests}
  \begin{tabular}{l l l}
  \toprule
  \textbf{Module} & \textbf{Test Case(s)} & \textbf{Comments}\\
  \midrule
  Collision Detection & U1, U4 & Checking correctness and performance \\
  IK Solver & U2, U5 & Ensuring correctness and numerical stability \\
  Path Planner & U3, U4 & Validates A* search efficiency and scalability \\
  \bottomrule
  \end{tabular}
\end{table}

\bibliographystyle{plainnat}
\bibliography{../../refs/References}
\newpage

\section{Appendix}

Any symbolic constants referenced in the test cases (like tolerances or maximum obstacle counts) can be listed here for easier maintenance.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

If we conduct a small-scale usability survey, we can place the questionnaire or script here.


\newpage{}


\end{document}